{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.14.3)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from beautifulsoup4) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from beautifulsoup4) (4.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "## Extracing and processing country indicators from https://data.un.org/en/index.html\n",
    "import requests #for extracting web content\n",
    "import pandas as pd, numpy as np #for data manipulation\n",
    "from bs4 import BeautifulSoup #for parsing web content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import country names data\n",
    "country_names = pd.read_csv(\"Countries1.csv\")\n",
    "\n",
    "#extract alphas column, converting values to lower case\n",
    "country_codes = country_names['Alpha2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target fields to extract\n",
    "TARGET_FIELDS = {\n",
    "    \"Region\": \"region\",\n",
    "    \"Population (000, 2025)\": \"population_th\",\n",
    "    \"GDP: Gross domestic product (million current US$)\": \"GDP\",\n",
    "    \"Life expectancy at birth (females/males, years)\": \"life_expectancy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target_indicators(tables):\n",
    "    \n",
    "    result = {\n",
    "        \"region\": None,\n",
    "        \"population_th\": None,\n",
    "        \"gdp\": None,\n",
    "        \"life_expectancy\": None\n",
    "    }\n",
    "    \n",
    "    # ---- GENERAL INFO TABLE ----\n",
    "    general_rows = tables[0].find_all(\"tr\")\n",
    "    \n",
    "    for row in general_rows:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if len(cols) < 3:\n",
    "            continue\n",
    "        \n",
    "        label = cols[0].lower()\n",
    "        value = cols[2]\n",
    "        \n",
    "        if \"region\" in label:\n",
    "            result[\"region\"] = value\n",
    "            \n",
    "        if \"population\" in label:\n",
    "            result[\"population_th\"] = value\n",
    "    \n",
    "    # ---- ECONOMIC TABLE ----\n",
    "    econ_rows = tables[1].find_all(\"tr\")\n",
    "    \n",
    "    for row in econ_rows:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if len(cols) < 4:\n",
    "            continue\n",
    "        \n",
    "        label = cols[0].lower()\n",
    "        \n",
    "        if \"gross domestic product\" in label:\n",
    "            result[\"gdp\"] = cols[2]   # choose 2020 column\n",
    "    \n",
    "    # ---- SOCIAL TABLE ----\n",
    "    social_rows = tables[2].find_all(\"tr\")\n",
    "    \n",
    "    for row in social_rows:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if len(cols) < 4:\n",
    "            continue\n",
    "        \n",
    "        label = cols[0].lower()\n",
    "        \n",
    "        if \"life expectancy\" in label:\n",
    "            result[\"life_expectancy\"] = cols[2]   # choose 2020\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Skipping (not found): {url}\")\n",
    "            return None\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        tables = soup.find_all(\"table\", class_=\"pure-table\")\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Afghanistan...\n",
      "Scraping Albania...\n",
      "Scraping Algeria...\n",
      "Scraping American Samoa...\n",
      "Scraping Andorra...\n",
      "Scraping Angola...\n",
      "Scraping Anguilla...\n",
      "Scraping Antigua and Barbuda...\n",
      "Scraping Argentina...\n",
      "Scraping Armenia...\n",
      "Scraping Aruba...\n",
      "Scraping Australia...\n",
      "Scraping Austria...\n",
      "Scraping Azerbaijan...\n",
      "Scraping Bahamas...\n",
      "Scraping Bahrain...\n",
      "Scraping Bangladesh...\n",
      "Scraping Barbados...\n",
      "Scraping Belarus...\n",
      "Scraping Belgium...\n",
      "Scraping Belize...\n",
      "Scraping Benin...\n",
      "Scraping Bermuda...\n",
      "Scraping Bhutan...\n",
      "Scraping Bolivia (Plurinational State of)...\n",
      "Scraping Bonaire, Sint Eustatius and Saba...\n",
      "Scraping Bosnia and Herzegovina...\n",
      "Scraping Botswana...\n",
      "Scraping Brazil...\n",
      "Scraping British Virgin Islands...\n",
      "Scraping Brunei Darussalam...\n",
      "Scraping Bulgaria...\n",
      "Scraping Burkina Faso...\n",
      "Scraping Burundi...\n",
      "Scraping Cabo Verde...\n",
      "Scraping Cambodia...\n",
      "Scraping Cameroon...\n",
      "Scraping Canada...\n",
      "Scraping Cayman Islands...\n",
      "Scraping Central African Republic...\n",
      "Scraping Chad...\n",
      "Scraping Channel Islands...\n",
      "Scraping Chile...\n",
      "Scraping China...\n",
      "Scraping China, Hong Kong SAR...\n",
      "Scraping China, Macao SAR...\n",
      "Scraping Colombia...\n",
      "Scraping Comoros...\n",
      "Scraping Congo...\n",
      "Scraping Cook Islands...\n",
      "Scraping Costa Rica...\n",
      "Scraping Côte d’Ivoire...\n",
      "Scraping Croatia...\n",
      "Scraping Cuba...\n",
      "Scraping Curaçao...\n",
      "Scraping Cyprus...\n",
      "Scraping Czechia...\n",
      "Scraping Democratic People's Republic of Korea...\n",
      "Scraping Democratic Republic of the Congo...\n",
      "Scraping Denmark...\n",
      "Scraping Djibouti...\n",
      "Scraping Dominica...\n",
      "Scraping Dominican Republic...\n",
      "Scraping Ecuador...\n",
      "Scraping Egypt...\n",
      "Scraping El Salvador...\n",
      "Scraping Equatorial Guinea...\n",
      "Scraping Eritrea...\n",
      "Scraping Estonia...\n",
      "Scraping Eswatini...\n",
      "Scraping Ethiopia...\n",
      "Scraping Falkland Islands (Malvinas)...\n",
      "Scraping Faroe Islands...\n",
      "Scraping Fiji...\n",
      "Scraping Finland...\n",
      "Scraping France...\n",
      "Scraping French Guiana...\n",
      "Scraping French Polynesia...\n",
      "Scraping Gabon...\n",
      "Scraping Gambia...\n",
      "Scraping Georgia...\n",
      "Scraping Germany...\n",
      "Scraping Ghana...\n",
      "Scraping Gibraltar...\n",
      "Scraping Greece...\n",
      "Scraping Greenland...\n",
      "Scraping Grenada...\n",
      "Scraping Guadeloupe...\n",
      "Scraping Guam...\n",
      "Scraping Guatemala...\n",
      "Scraping Guinea...\n",
      "Scraping Guinea-Bissau...\n",
      "Scraping Guyana...\n",
      "Scraping Haiti...\n",
      "Scraping Holy See...\n",
      "Scraping Honduras...\n",
      "Scraping Hungary...\n",
      "Scraping Iceland...\n",
      "Scraping India...\n",
      "Scraping Indonesia...\n",
      "Scraping Iran (Islamic Republic of)...\n",
      "Scraping Iraq...\n",
      "Scraping Ireland...\n",
      "Scraping Isle of Man...\n",
      "Scraping Israel...\n",
      "Scraping Italy...\n",
      "Scraping Jamaica...\n",
      "Scraping Japan...\n",
      "Scraping Jordan...\n",
      "Scraping Kazakhstan...\n",
      "Scraping Kenya...\n",
      "Scraping Kiribati...\n",
      "Scraping Kuwait...\n",
      "Scraping Kyrgyzstan...\n",
      "Scraping Lao People's Democratic Republic...\n",
      "Scraping Latvia...\n",
      "Scraping Lebanon...\n",
      "Scraping Lesotho...\n",
      "Scraping Liberia...\n",
      "Scraping Libya...\n",
      "Scraping Liechtenstein...\n",
      "Scraping Lithuania...\n",
      "Scraping Luxembourg...\n",
      "Scraping Madagascar...\n",
      "Scraping Malawi...\n",
      "Scraping Malaysia...\n",
      "Scraping Maldives...\n",
      "Scraping Mali...\n",
      "Scraping Malta...\n",
      "Scraping Marshall Islands...\n",
      "Scraping Martinique...\n",
      "Scraping Mauritania...\n",
      "Scraping Mauritius...\n",
      "Scraping Mayotte...\n",
      "Scraping Mexico...\n",
      "Scraping Micronesia (Federated States of)...\n",
      "Scraping Monaco...\n",
      "Scraping Mongolia...\n",
      "Scraping Montenegro...\n",
      "Scraping Montserrat...\n",
      "Scraping Morocco...\n",
      "Scraping Mozambique...\n",
      "Scraping Myanmar...\n",
      "Scraping Namibia...\n",
      "Skipping (not found): https://data.un.org/en/iso/nan.html\n",
      "Scraping Nauru...\n",
      "Scraping Nepal...\n",
      "Scraping Netherlands...\n",
      "Scraping New Caledonia...\n",
      "Scraping New Zealand...\n",
      "Scraping Nicaragua...\n",
      "Scraping Niger...\n",
      "Scraping Nigeria...\n",
      "Scraping Niue...\n",
      "Scraping North Macedonia...\n",
      "Scraping Northern Mariana Islands...\n",
      "Scraping Norway...\n",
      "Scraping Oman...\n",
      "Scraping Pakistan...\n",
      "Scraping Palau...\n",
      "Scraping Panama...\n",
      "Scraping Papua New Guinea...\n",
      "Scraping Paraguay...\n",
      "Scraping Peru...\n",
      "Scraping Philippines...\n",
      "Scraping Poland...\n",
      "Scraping Portugal...\n",
      "Scraping Puerto Rico...\n",
      "Scraping Qatar...\n",
      "Scraping Republic of Korea...\n",
      "Scraping Republic of Moldova...\n",
      "Scraping Réunion...\n",
      "Scraping Romania...\n",
      "Scraping Russian Federation...\n",
      "Scraping Rwanda...\n",
      "Scraping Saint Helena...\n",
      "Scraping Saint Kitts and Nevis...\n",
      "Scraping Saint Lucia...\n",
      "Scraping Saint Pierre and Miquelon...\n",
      "Scraping Saint Vincent and the Grenadines...\n",
      "Scraping Samoa...\n",
      "Scraping San Marino...\n",
      "Scraping Sao Tome and Principe...\n",
      "Scraping Saudi Arabia...\n",
      "Scraping Senegal...\n",
      "Scraping Serbia...\n",
      "Scraping Seychelles...\n",
      "Scraping Sierra Leone...\n",
      "Scraping Singapore...\n",
      "Scraping Sint Maarten (Dutch part)...\n",
      "Scraping Slovakia...\n",
      "Scraping Slovenia...\n",
      "Scraping Solomon Islands...\n",
      "Scraping Somalia...\n",
      "Scraping South Africa...\n",
      "Scraping South Sudan...\n",
      "Scraping Spain...\n",
      "Scraping Sri Lanka...\n",
      "Scraping State of Palestine...\n",
      "Scraping Sudan...\n",
      "Scraping Suriname...\n",
      "Scraping Sweden...\n",
      "Scraping Switzerland...\n",
      "Scraping Syrian Arab Republic...\n",
      "Scraping Tajikistan...\n",
      "Scraping Thailand...\n",
      "Scraping Timor-Leste...\n",
      "Scraping Togo...\n",
      "Scraping Tokelau...\n",
      "Scraping Tonga...\n",
      "Scraping Trinidad and Tobago...\n",
      "Scraping Tunisia...\n",
      "Scraping Türkiye...\n",
      "Scraping Turkmenistan...\n",
      "Scraping Turks and Caicos Islands...\n",
      "Scraping Tuvalu...\n",
      "Scraping Uganda...\n",
      "Scraping Ukraine...\n",
      "Scraping United Arab Emirates...\n",
      "Scraping United Kingdom...\n",
      "Scraping United Republic of Tanzania...\n",
      "Scraping United States of America...\n",
      "Scraping United States Virgin Islands...\n",
      "Scraping Uruguay...\n",
      "Scraping Uzbekistan...\n",
      "Scraping Vanuatu...\n",
      "Scraping Venezuela (Bolivarian Republic of)...\n",
      "Scraping Viet Nam...\n",
      "Scraping Wallis and Futuna Islands...\n",
      "Scraping Western Sahara...\n",
      "Scraping Yemen...\n",
      "Scraping Zambia...\n",
      "Scraping Zimbabwe...\n"
     ]
    }
   ],
   "source": [
    "all_country_data = []\n",
    "\n",
    "\n",
    "for country_name, iso_code in zip(\n",
    "        country_names[\"Country\"],\n",
    "        country_names[\"Alpha2\"].astype(str).str.lower()):\n",
    "    \n",
    "    url = f\"https://data.un.org/en/iso/{iso_code}.html\"\n",
    "    \n",
    "    print(f\"Scraping {country_name}...\")\n",
    "    \n",
    "    tables = extract_tables(url)\n",
    "    \n",
    "    if not tables:\n",
    "        continue\n",
    "    \n",
    "    indicators = extract_target_indicators(tables)\n",
    "    \n",
    "    indicators[\"country\"] = country_name\n",
    "    indicators[\"iso_alpha2\"] = iso_code.upper()\n",
    "    \n",
    "    all_country_data.append(indicators)\n",
    "\n",
    "all_country_data_df = pd.DataFrame(all_country_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            region  population_th       gdp         country iso_alpha2  \\\n",
      "0    Southern Asia        43844.0   19983.0     Afghanistan         AF   \n",
      "1  Southern Europe         2772.0   15163.0         Albania         AL   \n",
      "2  Northern Africa        47435.0  158975.0         Algeria         DZ   \n",
      "3        Polynesia           46.0       NaN  American Samoa         AS   \n",
      "4  Southern Europe           83.0    2891.0         Andorra         AD   \n",
      "\n",
      "   life_expectancy_female  life_expectancy_male  \n",
      "0                    64.7                  58.5  \n",
      "1                    80.3                  75.4  \n",
      "2                    74.9                  71.7  \n",
      "3                    75.7                  70.0  \n",
      "4                    83.8                  75.8  \n"
     ]
    }
   ],
   "source": [
    "print(all_country_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            region  population_th       gdp         country iso_alpha2  \\\n",
      "0    Southern Asia        43844.0   19983.0     Afghanistan         AF   \n",
      "1  Southern Europe         2772.0   15163.0         Albania         AL   \n",
      "2  Northern Africa        47435.0  158975.0         Algeria         DZ   \n",
      "3        Polynesia           46.0       NaN  American Samoa         AS   \n",
      "4  Southern Europe           83.0    2891.0         Andorra         AD   \n",
      "\n",
      "   life_expectancy_female  life_expectancy_male  \n",
      "0                    64.7                  58.5  \n",
      "1                    80.3                  75.4  \n",
      "2                    74.9                  71.7  \n",
      "3                    75.7                  70.0  \n",
      "4                    83.8                  75.8  \n"
     ]
    }
   ],
   "source": [
    "#Clean and save the data\n",
    "import re\n",
    "\n",
    "all_country_data_df[\"population_th\"] = (\n",
    "    all_country_data_df[\"population_th\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\" \", \"\", regex=False)\n",
    "    .str.replace(r\"[^0-9]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "all_country_data_df[\"population_th\"] = pd.to_numeric(\n",
    "    all_country_data_df[\"population_th\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "all_country_data_df[\"gdp\"] = (\n",
    "    all_country_data_df[\"gdp\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\" \", \"\", regex=False)\n",
    "    .str.replace(r\"[^0-9.-]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "all_country_data_df[\"gdp\"] = pd.to_numeric(\n",
    "    all_country_data_df[\"gdp\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "life_split = all_country_data_df[\"life_expectancy\"].str.split(\"/\", expand=True)\n",
    "\n",
    "all_country_data_df[\"life_expectancy_female\"] = pd.to_numeric(\n",
    "    life_split[0].str.replace(r\"[^0-9.]\", \"\", regex=True),\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "all_country_data_df[\"life_expectancy_male\"] = pd.to_numeric(\n",
    "    life_split[1].str.replace(r\"[^0-9.]\", \"\", regex=True),\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "all_country_data_df = all_country_data_df.drop(columns=[\"life_expectancy\"])\n",
    "\n",
    "\n",
    "print(all_country_data_df.head())\n",
    "\n",
    "all_country_data_df.to_csv(\"data/cleaned_country_xlsx/all_country_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
